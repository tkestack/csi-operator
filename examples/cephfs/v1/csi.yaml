apiVersion: storage.tkestack.io/v1
kind: CSI
metadata:
  finalizers:
    - storage.tkestack.io
  generation: 3
  name: cephfs
  namespace: kube-system
spec:
  configMaps:
    - data:
        config.json: '[{"clusterID":"cluster1","monitors":["192.168.0.1:6789","192.168.0.2:6789","192.168.0.3:6789"],"cephFS":{"subvolumeGroup":"group1"}},{"clusterID":"cluster2","monitors":["192.168.0.4:6789","192.168.0.5:6789","192.168.0.6:6789"],"cephFS":{"subvolumeGroup":"group2"}}]'
      metadata:
        creationTimestamp: null
        name: cephfs-csi-ceph-com-conf
        namespace: kube-system
  controller:
    attacher:
      image: mirrors.tencent.com/tkestack/csi-attacher:v1.1.0
      parameters: null
      resources:
        limits:
          cpu: 100m
          memory: 100Mi
    clusterRegistrar: null
    livenessProbe:
      image: mirrors.tencent.com/tkestack/livenessprobe:v1.1.0
      parameters:
        storage.tkestack.io/liveness-probe-port: "9818"
      resources: {}
    provisioner:
      image: mirrors.tencent.com/tkestack/csi-provisioner:v1.3.0
      parameters: null
      resources:
        limits:
          cpu: 100m
          memory: 100Mi
    replicas: 1
    resizer:
      image: mirrors.tencent.com/tkestack/csi-resizer:v0.5.0
      parameters: null
      resources:
        limits:
          cpu: 100m
          memory: 100Mi
    snapshotter: null
  driverName: cephfs.csi.ceph.com
  driverTemplate:
    template:
      metadata:
        creationTimestamp: null
      spec:
        containers:
          - args:
              - --nodeid=$(NODE_ID)
              - --endpoint=$(CSI_ENDPOINT)
              - --v=5
              - --drivername=cephfs.csi.ceph.com
              - --type=cephfs
            env:
              - name: NODE_ID
                valueFrom:
                  fieldRef:
                    fieldPath: spec.nodeName
              - name: POD_NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
              - name: POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
            image: mirrors.tencent.com/tkestack/cephcsi:v3.2.0
            imagePullPolicy: Always
            name: csi-cephfs
            resources: {}
            securityContext:
              allowPrivilegeEscalation: true
              capabilities:
                add:
                  - SYS_ADMIN
              privileged: true
            volumeMounts:
              - mountPath: /dev
                name: host-dev
              - mountPath: /sys
                name: host-sys
              - mountPath: /lib/modules
                name: lib-modules
                readOnly: true
              - mountPath: /etc/ceph-csi-config/
                name: ceph-csi-config
              - mountPath: /tmp/csi/keys
                name: keys-tmp-dir
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        tolerations:
          - effect: NoSchedule
            key: node-role.kubernetes.io/master
        volumes:
          - hostPath:
              path: /dev
            name: host-dev
          - hostPath:
              path: /sys
            name: host-sys
          - hostPath:
              path: /lib/modules
            name: lib-modules
          - configMap:
              name: cephfs-csi-ceph-com-conf
            name: ceph-csi-config
          - emptyDir:
              medium: Memory
            name: keys-tmp-dir
  node:
    livenessProbe:
      image: mirrors.tencent.com/tkestack/livenessprobe:v1.1.0
      parameters:
        storage.tkestack.io/liveness-probe-port: "9819"
      resources: {}
    nodeRegistrar:
      image: mirrors.tencent.com/tkestack/csi-node-driver-registrar:v1.1.0
      parameters: null
      resources: {}
  parameters:
    configs: |-
      [{
          "clusterID": "cluster1",
          "pools": "00000001-fs.data",
          "fsName": "00000001-fs",
          "adminID": "admin",
          "adminKey": "key",
          "monitors": "192.168.0.1:6789,192.168.0.2:6789,192.168.0.3:6789",
          "subvolumeGroup": "group1"
      }, {
          "clusterID": "cluster2",
          "pools": "00000001-fs.data",
          "fsName": "00000001-fs",
          "adminID": "admin",
          "adminKey": "key",
          "monitors": "192.168.0.4:6789,192.168.0.5:6789,192.168.0.6:6789",
          "subvolumeGroup": "group2"
      }]
  secrets:
    - data:
        adminID: YWRtaW4=
        adminKey: a2V5
      metadata:
        creationTimestamp: null
        name: cephfs-csi-ceph-com-secret-cluster1
        namespace: kube-system
    - data:
        adminID: YWRtaW4=
        adminKey: a2V5
      metadata:
        creationTimestamp: null
        name: cephfs-csi-ceph-com-secret-cluster2
        namespace: kube-system
  storageClasses:
    - allowVolumeExpansion: true
      metadata:
        creationTimestamp: null
        name: cephfs.csi.ceph.com-cluster1-00000001-fs.data
      parameters:
        adminid: admin
        clusterID: cluster1
        csi.storage.k8s.io/controller-expand-secret-name: cephfs-csi-ceph-com-secret-cluster1
        csi.storage.k8s.io/controller-expand-secret-namespace: kube-system
        csi.storage.k8s.io/controller-publish-secret-name: cephfs-csi-ceph-com-secret-cluster1
        csi.storage.k8s.io/controller-publish-secret-namespace: kube-system
        csi.storage.k8s.io/node-stage-secret-name: cephfs-csi-ceph-com-secret-cluster1
        csi.storage.k8s.io/node-stage-secret-namespace: kube-system
        csi.storage.k8s.io/provisioner-secret-name: cephfs-csi-ceph-com-secret-cluster1
        csi.storage.k8s.io/provisioner-secret-namespace: kube-system
        fsName: 00000001-fs
        pool: 00000001-fs.data
        provisionVolume: "true"
        userid: admin
      provisioner: cephfs.csi.ceph.com
      reclaimPolicy: Delete
    - allowVolumeExpansion: true
      metadata:
        creationTimestamp: null
        name: cephfs.csi.ceph.com-cluster2-00000001-fs.data
      parameters:
        adminid: admin
        clusterID: cluster2
        csi.storage.k8s.io/controller-expand-secret-name: cephfs-csi-ceph-com-secret-cluster2
        csi.storage.k8s.io/controller-expand-secret-namespace: kube-system
        csi.storage.k8s.io/controller-publish-secret-name: cephfs-csi-ceph-com-secret-cluster2
        csi.storage.k8s.io/controller-publish-secret-namespace: kube-system
        csi.storage.k8s.io/node-stage-secret-name: cephfs-csi-ceph-com-secret-cluster2
        csi.storage.k8s.io/node-stage-secret-namespace: kube-system
        csi.storage.k8s.io/provisioner-secret-name: cephfs-csi-ceph-com-secret-cluster2
        csi.storage.k8s.io/provisioner-secret-namespace: kube-system
        fsName: 00000001-fs
        pool: 00000001-fs.data
        provisionVolume: "true"
        userid: admin
      provisioner: cephfs.csi.ceph.com
      reclaimPolicy: Delete
  version: v1.0